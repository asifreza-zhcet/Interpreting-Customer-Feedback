{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d6c955",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a86c08",
   "metadata": {},
   "source": [
    "In the previous analysis, data preprocessing (feature engineering) and data exploration has been done. The next step will be to built the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396dc099",
   "metadata": {},
   "source": [
    "## Contents\n",
    "1. [Loading the clean data into Pandas DataFrame](#loading)\n",
    "2. [Stemming](#stem)\n",
    "3. [Text Embedding](#embedding)\n",
    "4. [Label Encoding](#encode)\n",
    "5. [Imbalanced Dataset](#imbalance)\n",
    "6. [Train Test Split](#split)\n",
    "7. [Model Training](#train)\n",
    "8. [Saving the models](#saving)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0f0936",
   "metadata": {},
   "source": [
    "<a id=loading></a>\n",
    "## 1. Loading the clean data into Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854e4e25",
   "metadata": {},
   "source": [
    "As in the previous it has been seen that the dataset contains more than 5,50,000 rows. So it will be very difficult to train such an enormous data. So we have selected a subset of the data (20% of the original data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46cc017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Review</th>\n",
       "      <th>Helpfulness</th>\n",
       "      <th>year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>Review character length</th>\n",
       "      <th>Review word length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>cherry pie larabar love cherry pie lara bar be...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>Sun</td>\n",
       "      <td>positive</td>\n",
       "      <td>111</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>melitta coffee melitta cafe collection blanc e...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>Sun</td>\n",
       "      <td>positive</td>\n",
       "      <td>404</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>great treat girls absolutely loved tuna heaven...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>Thu</td>\n",
       "      <td>positive</td>\n",
       "      <td>133</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>daily calming vendor fast dependable tea simpl...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2012</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>Tue</td>\n",
       "      <td>positive</td>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>best canned artichokes update lot happen coupl...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>Fri</td>\n",
       "      <td>positive</td>\n",
       "      <td>768</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                             Review  Helpfulness  \\\n",
       "0      5  cherry pie larabar love cherry pie lara bar be...     0.000000   \n",
       "1      5  melitta coffee melitta cafe collection blanc e...     0.000000   \n",
       "2      5  great treat girls absolutely loved tuna heaven...     0.000000   \n",
       "3      5  daily calming vendor fast dependable tea simpl...     0.000000   \n",
       "4      5  best canned artichokes update lot happen coupl...     0.666667   \n",
       "\n",
       "   year  Month  Date  Day sentiment  Review character length  \\\n",
       "0  2012      6    24  Sun  positive                      111   \n",
       "1  2010     10    24  Sun  positive                      404   \n",
       "2  2012      3    15  Thu  positive                      133   \n",
       "3  2012      3    27  Tue  positive                       93   \n",
       "4  2010      4    16  Fri  positive                      768   \n",
       "\n",
       "   Review word length  \n",
       "0                  20  \n",
       "1                  58  \n",
       "2                  22  \n",
       "3                  14  \n",
       "4                 119  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "df = joblib.load('./data_file/data.joblib')\n",
    "    \n",
    "# df = df.sample(frac=0.10,replace=False,ignore_index=True,random_state=1)\n",
    "df = df.sample(frac=0.20, random_state=1).reset_index(drop=True)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433cf2e1",
   "metadata": {},
   "source": [
    "<a id=stem></a>\n",
    "## 2. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa061a5",
   "metadata": {},
   "source": [
    "Stemming removes the inflection of words. This highly reduces the features required to train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6ecb0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         cherry pie larabar love cherry pie lara bar be...\n",
       "1         melitta coffee melitta cafe collection blanc e...\n",
       "2         great treat girls absolutely loved tuna heaven...\n",
       "3         daily calming vendor fast dependable tea simpl...\n",
       "4         best canned artichokes update lot happen coupl...\n",
       "                                ...                        \n",
       "113686    fruit nut delite bars think wonderful love com...\n",
       "113687    cats say weruvya older cats one hyperthyroidis...\n",
       "113688    greatest jerky jack links sweet hot jerky gera...\n",
       "113689    incredible addition baking replacing half flou...\n",
       "113690    good price initially little disappointed bonsa...\n",
       "Name: Review, Length: 113691, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    " \n",
    "ps = PorterStemmer()\n",
    "text_data = df['Review'].apply(lambda x: ps.stem(x))\n",
    "text_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf0e18c",
   "metadata": {},
   "source": [
    "<a id=embedding></a>\n",
    "## 3. Text Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0751d7",
   "metadata": {},
   "source": [
    "The process of converting the textual data into numbers which is possible for computers to work with is called text embedding. There are many methods to embed the text. These are word2vec, TFIDF and word vectorization. Here we have selected TFIDF as it is not so computationally expensive as word vectorization and also help to preserve the semantic meaning of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047a0f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113691, 6000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "model_tf = TfidfVectorizer(max_features=6000, ngram_range=(1,2))\n",
    "X = model_tf.fit_transform(text_data)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff37dbd8",
   "metadata": {},
   "source": [
    "<a id=encode></a>\n",
    "## 4. Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b9556",
   "metadata": {},
   "source": [
    "The sentiment column has three classes. To convert this class into it's corresponding numbers is called text encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5dd4f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "model_le = LabelEncoder()\n",
    "model_le.fit(['neutral','positive','negative'])\n",
    "y = model_le.transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc40811",
   "metadata": {},
   "source": [
    "<a id=imbalance></a>\n",
    "## 5. Checking if the dataset is imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca15dbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    16466\n",
       "neutral      8448\n",
       "positive    88777\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment')['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130129ef",
   "metadata": {},
   "source": [
    "It can be seen that the dataset is highly imbalanced. This may result in a biased model. So, we need to apply SMOTE technique and equalize the category of data. But before doing so we need to remove the inflection of the words using lemmatization and embed the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c3e3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(266331, 6000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "X_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66145051",
   "metadata": {},
   "source": [
    "<a id=split></a>\n",
    "## 6. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f94caf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train, y_test = train_test_split(X_res,y_res,random_state=0,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4576526e",
   "metadata": {},
   "source": [
    "<a id=train></a>\n",
    "## 7. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6ccc80",
   "metadata": {},
   "source": [
    "Here we have selected 5 machine learning models. The accuracy of each model is printed after training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee9f231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = LogisticRegression(max_iter=1000, multi_class='multinomial', n_jobs=-1), accuracy = 0.8737679989486924\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model = RandomForestClassifier(min_samples_leaf=2, n_jobs=-1), accuracy = 0.9535171870013329\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model = DecisionTreeClassifier(), accuracy = 0.8655077252332589\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model = BernoulliNB(), accuracy = 0.6786565791202809\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model = AdaBoostClassifier(), accuracy = 0.7092759119154448\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(n_jobs=-1,multi_class='multinomial', max_iter=1000)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(min_samples_leaf=2,n_jobs=-1)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "br = BernoulliNB()\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ab = AdaBoostClassifier()\n",
    "\n",
    "models = [lr, rf, dt, br, ab]\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f'Model = {model}, accuracy = {acc}')\n",
    "    print('-'*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc07916",
   "metadata": {},
   "source": [
    "From the above we conclude the best model is <b> RandomForest</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab216085",
   "metadata": {},
   "source": [
    "<a id=saving></a>\n",
    "## 8 Saving the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006ec41",
   "metadata": {},
   "source": [
    "We are saving the objects of PorterStammer, TFIDF, LalebEncoder and RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cec744ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/model_rand_fo.joblib']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(ps, './models/model_stem.joblib', compress = 3) \n",
    "joblib.dump(model_tf,'./models/model_tfidf.joblib', compress=3) \n",
    "joblib.dump(model_le, './models/model_label.joblib', compress=3) \n",
    "joblib.dump(rf, './models/model_rand_fo.joblib', compress=3) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d0b42",
   "metadata": {},
   "source": [
    "All the task of model building is done. Now what left is deployement."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
